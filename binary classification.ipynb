{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":451400,"sourceType":"datasetVersion","datasetId":205791}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport pandas as pd\nimport csv\nimport os\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom tensorflow.keras import layers, Sequential","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-09T04:35:28.381600Z","iopub.execute_input":"2023-12-09T04:35:28.382558Z","iopub.status.idle":"2023-12-09T04:35:28.388331Z","shell.execute_reply.started":"2023-12-09T04:35:28.382520Z","shell.execute_reply":"2023-12-09T04:35:28.387195Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#!pip install git+https://github.com/tensorflow/docs\n#! pip install tensorflow --upgrade","metadata":{"execution":{"iopub.status.busy":"2023-12-08T20:10:03.753342Z","iopub.execute_input":"2023-12-08T20:10:03.753986Z","iopub.status.idle":"2023-12-08T20:10:03.757906Z","shell.execute_reply.started":"2023-12-08T20:10:03.753957Z","shell.execute_reply":"2023-12-08T20:10:03.756853Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:35:29.523706Z","iopub.execute_input":"2023-12-09T04:35:29.524631Z","iopub.status.idle":"2023-12-09T04:35:29.529328Z","shell.execute_reply.started":"2023-12-09T04:35:29.524593Z","shell.execute_reply":"2023-12-09T04:35:29.528231Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Specify the directory where your CSV files are located\ndirectory_path = '/kaggle/input/dcsass-dataset/DCSASS Dataset/Labels'\nvideos_directory = '/kaggle/input/dcsass-dataset/DCSASS Dataset'\n\ndef prepareParentVideoPath(video_name):\n    video_path = \"\"\n    done = False\n    for c in video_name:\n        if(done and c == '_'):\n            return video_path\n        video_path += c\n        if(c == '_'):\n            done = True\n    return \"\"\n        \n# Initialize empty lists to store video names and abnormal behaviors\nvideo_paths = []\nlabels = []\n\n# Iterate over each file in the directory\nfor filename in os.listdir(directory_path):\n    if filename.endswith('.csv'):\n        file_path = os.path.join(directory_path, filename)\n\n        # Open the CSV file and read its contents\n        with open(file_path, 'r') as csv_file:\n            csv_reader = csv.reader(csv_file)\n\n            # Skip the header if it exists\n            next(csv_reader, None)\n\n            # Iterate over each row in the CSV file\n            for row in csv_reader:\n                # Assuming the first column is the video name and the second column is the abnormal behavior\n                video_path = videos_directory + '/' + filename[:-4] + '/' + prepareParentVideoPath(row[0]) + '.mp4' + '/' + row[0] + '.mp4' #row[0]\n                label = row[2]  # Convert the value to an integer\n\n                # Append the values to the respective lists\n                video_paths.append(video_path)\n                labels.append(label)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:35:30.724645Z","iopub.execute_input":"2023-12-09T04:35:30.725451Z","iopub.status.idle":"2023-12-09T04:35:30.841057Z","shell.execute_reply.started":"2023-12-09T04:35:30.725413Z","shell.execute_reply":"2023-12-09T04:35:30.840193Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data = {'Video Path': video_paths, 'Label': labels}\ndf = pd.DataFrame(data)\nprint(df.head())\nprint(df.tail())","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:35:34.710497Z","iopub.execute_input":"2023-12-09T04:35:34.711534Z","iopub.status.idle":"2023-12-09T04:35:34.723635Z","shell.execute_reply.started":"2023-12-09T04:35:34.711494Z","shell.execute_reply":"2023-12-09T04:35:34.722693Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"                                          Video Path Label\n0  /kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...     0\n1  /kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...     1\n2  /kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...     1\n3  /kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...     0\n4  /kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...     1\n                                              Video Path Label\n16613  /kaggle/input/dcsass-dataset/DCSASS Dataset/Fi...     0\n16614  /kaggle/input/dcsass-dataset/DCSASS Dataset/Fi...     0\n16615  /kaggle/input/dcsass-dataset/DCSASS Dataset/Fi...     0\n16616  /kaggle/input/dcsass-dataset/DCSASS Dataset/Fi...     0\n16617  /kaggle/input/dcsass-dataset/DCSASS Dataset/Fi...     0\n","output_type":"stream"}]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n  except RuntimeError as e:\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T03:54:16.617755Z","iopub.execute_input":"2023-12-09T03:54:16.618923Z","iopub.status.idle":"2023-12-09T03:54:16.625619Z","shell.execute_reply.started":"2023-12-09T03:54:16.618852Z","shell.execute_reply":"2023-12-09T03:54:16.624525Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Virtual devices cannot be modified after being initialized\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(\"Tensorflow version \" + tf.__version__)\n# AUTO = tf.data.experimental.AUTOTUNE\n\n# # Detect TPU, return appropriate distribution strategy\n# try:\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n#     print('Running on TPU ', tpu.master())\n# except ValueError:\n#     tpu = None\n\n# if tpu:\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# else:\n#     strategy = tf.distribute.get_strategy() \n\n# print(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T20:10:04.392346Z","iopub.execute_input":"2023-12-08T20:10:04.393266Z","iopub.status.idle":"2023-12-08T20:10:04.411126Z","shell.execute_reply.started":"2023-12-08T20:10:04.393227Z","shell.execute_reply":"2023-12-08T20:10:04.410256Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T03:54:22.433082Z","iopub.execute_input":"2023-12-09T03:54:22.433905Z","iopub.status.idle":"2023-12-09T03:54:22.451153Z","shell.execute_reply.started":"2023-12-09T03:54:22.433858Z","shell.execute_reply":"2023-12-09T03:54:22.450212Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                              Video Path Label\n4026   /kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...     0\n7426   /kaggle/input/dcsass-dataset/DCSASS Dataset/Ar...     1\n9578   /kaggle/input/dcsass-dataset/DCSASS Dataset/St...     0\n14175  /kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...     0\n5432   /kaggle/input/dcsass-dataset/DCSASS Dataset/Va...     0\n3549   /kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...     0\n15784  /kaggle/input/dcsass-dataset/DCSASS Dataset/As...     0\n823    /kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...     1\n9589   /kaggle/input/dcsass-dataset/DCSASS Dataset/St...     1\n6466   /kaggle/input/dcsass-dataset/DCSASS Dataset/Sh...     1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Video Path</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4026</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7426</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ar...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9578</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/St...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14175</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5432</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Va...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3549</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15784</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/As...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>823</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9589</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/St...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6466</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Sh...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Specify the test size (e.g., 0.2 for 20% test data)\ntest_size = 0.2\n\n# Split the DataFrame into training and testing sets\ntrain_df, test_df = train_test_split(df, test_size=test_size)\n\ntrain_df[train_df['Label'] != '']","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:35:40.058464Z","iopub.execute_input":"2023-12-09T04:35:40.059234Z","iopub.status.idle":"2023-12-09T04:35:40.078621Z","shell.execute_reply.started":"2023-12-09T04:35:40.059198Z","shell.execute_reply":"2023-12-09T04:35:40.077690Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                              Video Path Label\n1279   /kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...     0\n8860   /kaggle/input/dcsass-dataset/DCSASS Dataset/St...     0\n10820  /kaggle/input/dcsass-dataset/DCSASS Dataset/Sh...     1\n4752   /kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...     0\n592    /kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...     1\n...                                                  ...   ...\n12429  /kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...     0\n4184   /kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...     1\n13943  /kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...     0\n13787  /kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...     0\n9654   /kaggle/input/dcsass-dataset/DCSASS Dataset/St...     1\n\n[13293 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Video Path</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1279</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8860</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/St...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10820</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Sh...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4752</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12429</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4184</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13943</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13787</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ro...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9654</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/St...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>13293 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T03:54:27.499449Z","iopub.execute_input":"2023-12-09T03:54:27.500395Z","iopub.status.idle":"2023-12-09T03:54:27.510021Z","shell.execute_reply.started":"2023-12-09T03:54:27.500359Z","shell.execute_reply":"2023-12-09T03:54:27.508839Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                             Video Path Label\n5581  /kaggle/input/dcsass-dataset/DCSASS Dataset/Va...     0\n9839  /kaggle/input/dcsass-dataset/DCSASS Dataset/Ar...     0\n5143  /kaggle/input/dcsass-dataset/DCSASS Dataset/Va...     0\n6803  /kaggle/input/dcsass-dataset/DCSASS Dataset/Sh...     0\n1176  /kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...     1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Video Path</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5581</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Va...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9839</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Ar...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5143</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Va...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6803</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1176</th>\n      <td>/kaggle/input/dcsass-dataset/DCSASS Dataset/Bu...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Feed the videos to a network:**","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 224\n\ndef load_video(path, max_frames=60, resize=(IMG_SIZE, IMG_SIZE)):\n    cap = cv2.VideoCapture(path)\n    frames = []\n\n    try:\n        for i in range(max_frames):\n            ret, frame = cap.read()\n            if not ret:\n                break\n\n            frame = cv2.resize(frame, resize)\n            frames.append(frame/255)\n\n    finally:\n        cap.release()\n\n    return frames","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:35:45.356021Z","iopub.execute_input":"2023-12-09T04:35:45.356841Z","iopub.status.idle":"2023-12-09T04:35:45.362811Z","shell.execute_reply.started":"2023-12-09T04:35:45.356805Z","shell.execute_reply":"2023-12-09T04:35:45.361785Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature extraction**","metadata":{}},{"cell_type":"code","source":"\n# def build_feature_extractor():\n    \n#     feature_extractor = keras.applications.ResNet50(\n#         weights=\"imagenet\",\n#         include_top=False,\n#         pooling=\"avg\",\n#         input_shape=(IMG_SIZE, IMG_SIZE, 3),\n#     )\n#     preprocess_input = keras.applications.resnet50.preprocess_input\n\n#     inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n#     preprocessed = preprocess_input(inputs)\n\n#     outputs = feature_extractor(preprocessed)\n                         \n#     return keras.Model(inputs, outputs, name=\"feature_extractor\")\n\n\n# feature_extractor = build_feature_extractor()","metadata":{"execution":{"iopub.status.busy":"2023-12-08T20:10:04.472821Z","iopub.execute_input":"2023-12-08T20:10:04.473246Z","iopub.status.idle":"2023-12-08T20:10:04.481363Z","shell.execute_reply.started":"2023-12-08T20:10:04.473221Z","shell.execute_reply":"2023-12-08T20:10:04.480608Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Define hyperparameters\n\nIMG_SIZE = 224\nBATCH_SIZE = 64\nEPOCHS = 100\nMAX_SEQ_LENGTH = 60\nNUM_FEATURES = 2048\ncnt = 0","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:35:45.884739Z","iopub.execute_input":"2023-12-09T04:35:45.885480Z","iopub.status.idle":"2023-12-09T04:35:45.890324Z","shell.execute_reply.started":"2023-12-09T04:35:45.885444Z","shell.execute_reply":"2023-12-09T04:35:45.889248Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\ndef prepare_all_videos(df):\n    \n    num_samples = len(df)\n    print(num_samples, MAX_SEQ_LENGTH)\n        \n    labels = df['Label'].to_list()\n    video_paths = df['Video Path'].to_list()\n    frame_features = []\n    lbl = []\n\n    # For each video.\n    for idx, path in enumerate(video_paths):\n        if(labels[idx] not in ['0', '1']):\n            continue\n        frames = load_video(path)\n        if(len(frames) == 30):\n            frame_features.append(frames)\n            lbl.append(int(labels[idx]))\n        \n        if(len(frames) == 60):\n            if(labels[idx] not in ['0', '1']):\n                continue\n            f = []\n            for i, frame in enumerate(frames):\n                if i%2 == 0:\n                    f.append(frame)\n            frame_features.append(f)\n            lbl.append(int(labels[idx]))\n            print(idx, path)\n\n\n    return frame_features, lbl\n\n\n#train_data, train_labels = prepare_all_videos(train_df.sample(100))\ntest_data, test_labels = prepare_all_videos(test_df.sample(200))\n\n#print(f\"Frame features in train set: {len(train_data)}\")\nprint(f\"Frame features in test set: {len(test_data)}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:36:15.337732Z","iopub.execute_input":"2023-12-09T04:36:15.338681Z","iopub.status.idle":"2023-12-09T04:36:23.306129Z","shell.execute_reply.started":"2023-12-09T04:36:15.338649Z","shell.execute_reply":"2023-12-09T04:36:23.305199Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"200 60\n0 /kaggle/input/dcsass-dataset/DCSASS Dataset/Fighting/Fighting014_x264.mp4/Fighting014_x264_9.mp4\n1 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson014_x264.mp4/Arson014_x264_26.mp4\n2 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse008_x264.mp4/Abuse008_x264_30.mp4\n3 /kaggle/input/dcsass-dataset/DCSASS Dataset/RoadAccidents/RoadAccidents016_x264.mp4/RoadAccidents016_x264_30.mp4\n5 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery008_x264.mp4/Robbery008_x264_12.mp4\n6 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery105_x264.mp4/Robbery105_x264_4.mp4\n7 /kaggle/input/dcsass-dataset/DCSASS Dataset/RoadAccidents/RoadAccidents011_x264.mp4/RoadAccidents011_x264_23.mp4\n8 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery056_x264.mp4/Robbery056_x264_28.mp4\n9 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson039_x264.mp4/Arson039_x264_6.mp4\n11 /kaggle/input/dcsass-dataset/DCSASS Dataset/Assault/Assault011_x264.mp4/Assault011_x264_4.mp4\n13 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shooting/Shooting022_x264.mp4/Shooting022_x264_13.mp4\n14 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson034_x264.mp4/Arson034_x264_18.mp4\n16 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary046_x264.mp4/Burglary046_x264_6.mp4\n18 /kaggle/input/dcsass-dataset/DCSASS Dataset/Fighting/Fighting014_x264.mp4/Fighting014_x264_13.mp4\n19 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery142_x264.mp4/Robbery142_x264_12.mp4\n20 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shoplifting/Shoplifting015_x264.mp4/Shoplifting015_x264_12.mp4\n21 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing007_x264.mp4/Stealing007_x264_2.mp4\n22 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson041_x264.mp4/Arson041_x264_22.mp4\n23 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse003_x264.mp4/Abuse003_x264_12.mp4\n24 /kaggle/input/dcsass-dataset/DCSASS Dataset/Assault/Assault017_x264.mp4/Assault017_x264_4.mp4\n26 /kaggle/input/dcsass-dataset/DCSASS Dataset/Explosion/Explosion006_x264.mp4/Explosion006_x264_2.mp4\n28 /kaggle/input/dcsass-dataset/DCSASS Dataset/RoadAccidents/RoadAccidents117_x264.mp4/RoadAccidents117_x264_16.mp4\n30 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery081_x264.mp4/Robbery081_x264_18.mp4\n31 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary086_x264.mp4/Burglary086_x264_15.mp4\n32 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing044_x264.mp4/Stealing044_x264_4.mp4\n35 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse004_x264.mp4/Abuse004_x264_2.mp4\n39 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arrest/Arrest036_x264.mp4/Arrest036_x264_10.mp4\n40 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shoplifting/Shoplifting042_x264.mp4/Shoplifting042_x264_26.mp4\n41 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson028_x264.mp4/Arson028_x264_9.mp4\n42 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arrest/Arrest038_x264.mp4/Arrest038_x264_28.mp4\n43 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse006_x264.mp4/Abuse006_x264_17.mp4\n44 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shooting/Shooting031_x264.mp4/Shooting031_x264_14.mp4\n45 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery097_x264.mp4/Robbery097_x264_21.mp4\n46 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing107_x264.mp4/Stealing107_x264_21.mp4\n52 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shoplifting/Shoplifting015_x264.mp4/Shoplifting015_x264_19.mp4\n53 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse026_x264.mp4/Abuse026_x264_21.mp4\n54 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery100_x264.mp4/Robbery100_x264_10.mp4\n56 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson045_x264.mp4/Arson045_x264_9.mp4\n57 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary082_x264.mp4/Burglary082_x264_8.mp4\n58 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery114_x264.mp4/Robbery114_x264_19.mp4\n61 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse012_x264.mp4/Abuse012_x264_11.mp4\n62 /kaggle/input/dcsass-dataset/DCSASS Dataset/Assault/Assault004_x264.mp4/Assault004_x264_23.mp4\n63 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse006_x264.mp4/Abuse006_x264_27.mp4\n64 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing044_x264.mp4/Stealing044_x264_3.mp4\n65 /kaggle/input/dcsass-dataset/DCSASS Dataset/Assault/Assault037_x264.mp4/Assault037_x264_9.mp4\n67 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery007_x264.mp4/Robbery007_x264_27.mp4\n68 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shoplifting/Shoplifting053_x264.mp4/Shoplifting053_x264_1.mp4\n76 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery078_x264.mp4/Robbery078_x264_4.mp4\n81 /kaggle/input/dcsass-dataset/DCSASS Dataset/Vandalism/Vandalism004_x264.mp4/Vandalism004_x264_25.mp4\n82 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery118_x264.mp4/Robbery118_x264_2.mp4\n84 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson027_x264.mp4/Arson027_x264_7.mp4\n85 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arrest/Arrest003_x264.mp4/Arrest003_x264_0.mp4\n87 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery052_x264.mp4/Robbery052_x264_21.mp4\n89 /kaggle/input/dcsass-dataset/DCSASS Dataset/RoadAccidents/RoadAccidents011_x264.mp4/RoadAccidents011_x264_16.mp4\n91 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse004_x264.mp4/Abuse004_x264_1.mp4\n92 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing042_x264.mp4/Stealing042_x264_8.mp4\n93 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arrest/Arrest038_x264.mp4/Arrest038_x264_9.mp4\n94 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse001_x264.mp4/Abuse001_x264_4.mp4\n95 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shooting/Shooting020_x264.mp4/Shooting020_x264_5.mp4\n96 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arrest/Arrest001_x264.mp4/Arrest001_x264_15.mp4\n98 /kaggle/input/dcsass-dataset/DCSASS Dataset/Vandalism/Vandalism033_x264.mp4/Vandalism033_x264_22.mp4\n99 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arrest/Arrest041_x264.mp4/Arrest041_x264_27.mp4\n101 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson003_x264.mp4/Arson003_x264_17.mp4\n103 /kaggle/input/dcsass-dataset/DCSASS Dataset/RoadAccidents/RoadAccidents011_x264.mp4/RoadAccidents011_x264_10.mp4\n104 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shooting/Shooting050_x264.mp4/Shooting050_x264_15.mp4\n110 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing016_x264.mp4/Stealing016_x264_27.mp4\n111 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary085_x264.mp4/Burglary085_x264_11.mp4\n112 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery078_x264.mp4/Robbery078_x264_12.mp4\n113 /kaggle/input/dcsass-dataset/DCSASS Dataset/Assault/Assault004_x264.mp4/Assault004_x264_25.mp4\n114 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing075_x264.mp4/Stealing075_x264_16.mp4\n120 /kaggle/input/dcsass-dataset/DCSASS Dataset/Assault/Assault009_x264.mp4/Assault009_x264_9.mp4\n122 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery062_x264.mp4/Robbery062_x264_6.mp4\n125 /kaggle/input/dcsass-dataset/DCSASS Dataset/Fighting/Fighting014_x264.mp4/Fighting014_x264_16.mp4\n126 /kaggle/input/dcsass-dataset/DCSASS Dataset/Vandalism/Vandalism004_x264.mp4/Vandalism004_x264_22.mp4\n127 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery030_x264.mp4/Robbery030_x264_0.mp4\n129 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse012_x264.mp4/Abuse012_x264_28.mp4\n132 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery054_x264.mp4/Robbery054_x264_11.mp4\n133 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery105_x264.mp4/Robbery105_x264_30.mp4\n134 /kaggle/input/dcsass-dataset/DCSASS Dataset/Assault/Assault013_x264.mp4/Assault013_x264_3.mp4\n135 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson040_x264.mp4/Arson040_x264_9.mp4\n137 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing112_x264.mp4/Stealing112_x264_28.mp4\n138 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery109_x264.mp4/Robbery109_x264_8.mp4\n140 /kaggle/input/dcsass-dataset/DCSASS Dataset/Vandalism/Vandalism044_x264.mp4/Vandalism044_x264_0.mp4\n142 /kaggle/input/dcsass-dataset/DCSASS Dataset/Vandalism/Vandalism044_x264.mp4/Vandalism044_x264_3.mp4\n143 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing018_x264.mp4/Stealing018_x264_13.mp4\n144 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary014_x264.mp4/Burglary014_x264_8.mp4\n145 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing101_x264.mp4/Stealing101_x264_29.mp4\n146 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary046_x264.mp4/Burglary046_x264_21.mp4\n147 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary022_x264.mp4/Burglary022_x264_17.mp4\n148 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse035_x264.mp4/Abuse035_x264_30.mp4\n149 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shooting/Shooting050_x264.mp4/Shooting050_x264_1.mp4\n151 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arson/Arson027_x264.mp4/Arson027_x264_9.mp4\n158 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shoplifting/Shoplifting001_x264.mp4/Shoplifting001_x264_12.mp4\n159 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery117_x264.mp4/Robbery117_x264_24.mp4\n161 /kaggle/input/dcsass-dataset/DCSASS Dataset/RoadAccidents/RoadAccidents011_x264.mp4/RoadAccidents011_x264_0.mp4\n162 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery066_x264.mp4/Robbery066_x264_13.mp4\n163 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery137_x264.mp4/Robbery137_x264_30.mp4\n164 /kaggle/input/dcsass-dataset/DCSASS Dataset/RoadAccidents/RoadAccidents127_x264.mp4/RoadAccidents127_x264_19.mp4\n165 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery148_x264.mp4/Robbery148_x264_23.mp4\n166 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing104_x264.mp4/Stealing104_x264_1.mp4\n167 /kaggle/input/dcsass-dataset/DCSASS Dataset/Arrest/Arrest048_x264.mp4/Arrest048_x264_12.mp4\n168 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary014_x264.mp4/Burglary014_x264_2.mp4\n170 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery094_x264.mp4/Robbery094_x264_13.mp4\n172 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing010_x264.mp4/Stealing010_x264_18.mp4\n173 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shoplifting/Shoplifting053_x264.mp4/Shoplifting053_x264_3.mp4\n174 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shooting/Shooting050_x264.mp4/Shooting050_x264_31.mp4\n176 /kaggle/input/dcsass-dataset/DCSASS Dataset/Assault/Assault047_x264.mp4/Assault047_x264_20.mp4\n178 /kaggle/input/dcsass-dataset/DCSASS Dataset/Abuse/Abuse001_x264.mp4/Abuse001_x264_17.mp4\n180 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing075_x264.mp4/Stealing075_x264_14.mp4\n181 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary023_x264.mp4/Burglary023_x264_18.mp4\n183 /kaggle/input/dcsass-dataset/DCSASS Dataset/Fighting/Fighting009_x264.mp4/Fighting009_x264_7.mp4\n188 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing026_x264.mp4/Stealing026_x264_17.mp4\n189 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery129_x264.mp4/Robbery129_x264_30.mp4\n194 /kaggle/input/dcsass-dataset/DCSASS Dataset/Stealing/Stealing011_x264.mp4/Stealing011_x264_8.mp4\n195 /kaggle/input/dcsass-dataset/DCSASS Dataset/Burglary/Burglary035_x264.mp4/Burglary035_x264_26.mp4\n198 /kaggle/input/dcsass-dataset/DCSASS Dataset/Shoplifting/Shoplifting021_x264.mp4/Shoplifting021_x264_17.mp4\n199 /kaggle/input/dcsass-dataset/DCSASS Dataset/Robbery/Robbery109_x264.mp4/Robbery109_x264_27.mp4\nFrame features in test set: 198\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(train_labels))\ntrain_df = train_df[(train_df['Label'] == '0') | (train_df['Label'] == '1')]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T03:55:06.674836Z","iopub.execute_input":"2023-12-09T03:55:06.675791Z","iopub.status.idle":"2023-12-09T03:55:06.687322Z","shell.execute_reply.started":"2023-12-09T03:55:06.675752Z","shell.execute_reply":"2023-12-09T03:55:06.686293Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"100\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df['Label'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T03:55:08.012457Z","iopub.execute_input":"2023-12-09T03:55:08.013257Z","iopub.status.idle":"2023-12-09T03:55:08.023802Z","shell.execute_reply.started":"2023-12-09T03:55:08.013221Z","shell.execute_reply":"2023-12-09T03:55:08.022726Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array(['0', '1'], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"**The sequence model**","metadata":{}},{"cell_type":"code","source":"# train_data = train_data[:100]\n# train_labels = train_labels[:100]","metadata":{"execution":{"iopub.status.busy":"2023-12-08T20:10:14.296951Z","iopub.execute_input":"2023-12-08T20:10:14.297233Z","iopub.status.idle":"2023-12-08T20:10:14.305189Z","shell.execute_reply.started":"2023-12-08T20:10:14.297205Z","shell.execute_reply":"2023-12-08T20:10:14.304344Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Utility for our sequence model.\ndef get_sequence_model():\n\n    frame_features_input = (MAX_SEQ_LENGTH, NUM_FEATURES)\n    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n\n    model = Sequential()\n\n    model.add(ConvLSTM2D(filters=4, kernel_size=(3, 3), activation='tanh', data_format='channels_last', \n                        recurrent_dropout=0.2, return_sequences=True, input_shape=(30, IMG_SIZE, IMG_SIZE, 3)))\n\n    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n    model.add(TimeDistributed(Dropout(0.2)))\n\n    model.add(ConvLSTM2D(filters=8, kernel_size=(3, 3), activation='tanh', data_format='channels_last', \n                        recurrent_dropout=0.2, return_sequences=True))\n\n    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n    model.add(TimeDistributed(Dropout(0.2)))\n\n    model.add(ConvLSTM2D(filters=14, kernel_size=(3, 3), activation='tanh', data_format='channels_last', \n                        recurrent_dropout=0.2, return_sequences=True))\n\n    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n    model.add(TimeDistributed(Dropout(0.2)))\n\n    model.add(ConvLSTM2D(filters=16, kernel_size=(3, 3), activation='tanh', data_format='channels_last', \n                        recurrent_dropout=0.2, return_sequences=True))\n\n    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n    # model.add(TimeDistributed(Dropout(0.2)))\n\n    model.add(Flatten())\n\n    model.add(Dense(1, activation=\"sigmoid\"))\n\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    model.summary()\n    \n    return model\n\nEPOCHS = 10\n# Utility for running experiments.\n# def run_experiment():\n#     filepath = \"./model/video_classifier\"\n#     checkpoint = keras.callbacks.ModelCheckpoint(\n#         filepath, save_weights_only=True, save_best_only=True, verbose=1\n#     )\n\n#     seq_model = get_sequence_model()\n#     history = seq_model.fit(\n#         train_data,\n#         np.array(train_labels),\n#         validation_split=0.2,\n#         epochs=EPOCHS,\n#         callbacks=[checkpoint],\n#     )\n\n#     seq_model.load_weights(filepath)\n#     _, accuracy = seq_model.evaluate(test_data, np.array(test_labels))\n#     print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n\n#     return history, seq_model\n\n\n# _, sequence_model = run_experiment()","metadata":{"execution":{"iopub.status.busy":"2023-12-08T20:10:14.306399Z","iopub.execute_input":"2023-12-08T20:10:14.306674Z","iopub.status.idle":"2023-12-08T20:10:14.320273Z","shell.execute_reply.started":"2023-12-08T20:10:14.306646Z","shell.execute_reply":"2023-12-08T20:10:14.319309Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#pip install --upgrade tensorflow\nprint(len(train_labels))","metadata":{"execution":{"iopub.status.busy":"2023-12-08T20:10:14.321377Z","iopub.execute_input":"2023-12-08T20:10:14.321655Z","iopub.status.idle":"2023-12-08T20:10:14.334300Z","shell.execute_reply.started":"2023-12-08T20:10:14.321629Z","shell.execute_reply":"2023-12-08T20:10:14.333418Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"100\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom tensorflow.keras.utils import Sequence\n\nclass VideoDataGenerator(Sequence):\n    def __init__(self, video_paths, labels, batch_size, frame_shape=(224, 224), shuffle=True):\n        self.video_paths = video_paths\n        self.labels = labels\n        self.batch_size = batch_size\n        self.frame_shape = frame_shape\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.ceil(len(self.video_paths) / self.batch_size))\n\n    def __getitem__(self, index):\n        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n        #batch_video_paths = [self.video_paths[i] for i in indices]\n        batch_labels = []\n\n        batch_data = []\n        \n        for i in indices:\n            frames = self.load_and_preprocess_video(self.video_paths[i])\n            if(len(frames) == 30):\n                batch_data.append(frames)\n                batch_labels.append(int(self.labels[i]))\n        \n#         for video_path in batch_video_paths:\n#             frames = self.load_and_preprocess_video(video_path)\n#             batch_data.append(frames)\n\n        return np.array(batch_data), np.array(batch_labels)\n\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.video_paths))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n    def load_and_preprocess_video(self, video_path):\n        cap = cv2.VideoCapture(video_path)\n        frames = []\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break\n            # Resize frame to the desired shape\n            frame = cv2.resize(frame, self.frame_shape)\n            # Perform any additional preprocessing if needed\n            # (e.g., normalization, data augmentation)\n            frames.append(frame/255)\n        cap.release()\n#         print(len(frames[:30]))\n        return np.array(frames[:30])\n\n# Example usage\nvideo_paths = train_df['Video Path'].to_list()\nvideo_labels = train_df['Label'].to_list()\nbatch_size = 2\n\nvideo_generator = VideoDataGenerator(video_paths, video_labels, batch_size)\n\nmodel.fit(video_generator, epochs=5, steps_per_epoch=len(video_paths)//batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T21:18:43.006248Z","iopub.execute_input":"2023-12-08T21:18:43.007345Z","iopub.status.idle":"2023-12-09T03:35:56.671816Z","shell.execute_reply.started":"2023-12-08T21:18:43.007307Z","shell.execute_reply":"2023-12-09T03:35:56.670911Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Epoch 1/5\n6646/6646 [==============================] - 4545s 684ms/step - loss: 0.6232 - accuracy: 0.6565\nEpoch 2/5\n6646/6646 [==============================] - 4495s 676ms/step - loss: 0.5231 - accuracy: 0.7488\nEpoch 3/5\n6646/6646 [==============================] - 4564s 687ms/step - loss: 0.4775 - accuracy: 0.7795\nEpoch 4/5\n6646/6646 [==============================] - 4534s 682ms/step - loss: 0.4460 - accuracy: 0.7975\nEpoch 5/5\n6646/6646 [==============================] - 4496s 677ms/step - loss: 0.4169 - accuracy: 0.8123\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7e30e9e3eef0>"},"metadata":{}}]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\n\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\nmodel = get_sequence_model()\ncheckpoint_filepath = \"model\"\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    save_best_only=True,  # Set to True if you want to save only the best model\n    monitor='val_loss',   # You can choose the metric to monitor, e.g., 'val_accuracy'\n    mode='min',           # 'min' or 'max' depending on the metric (e.g., 'min' for loss, 'max' for accuracy)\n    verbose=1\n)\nmodel.fit(\n        x = np.array(train_data),\n        y = np.array(train_labels), \n        batch_size = 4, \n        validation_split = 0.2,\n        epochs = 5, \n        shuffle = True,\n        callbacks = [early_stopping_callback, model_checkpoint_callback]\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-08T20:10:14.335413Z","iopub.execute_input":"2023-12-08T20:10:14.335699Z","iopub.status.idle":"2023-12-08T20:11:27.541793Z","shell.execute_reply.started":"2023-12-08T20:10:14.335676Z","shell.execute_reply":"2023-12-08T20:11:27.540931Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv_lstm2d (ConvLSTM2D)    (None, 30, 222, 222, 4)   1024      \n                                                                 \n max_pooling3d (MaxPooling3  (None, 30, 111, 111, 4)   0         \n D)                                                              \n                                                                 \n time_distributed (TimeDist  (None, 30, 111, 111, 4)   0         \n ributed)                                                        \n                                                                 \n conv_lstm2d_1 (ConvLSTM2D)  (None, 30, 109, 109, 8)   3488      \n                                                                 \n max_pooling3d_1 (MaxPoolin  (None, 30, 55, 55, 8)     0         \n g3D)                                                            \n                                                                 \n time_distributed_1 (TimeDi  (None, 30, 55, 55, 8)     0         \n stributed)                                                      \n                                                                 \n conv_lstm2d_2 (ConvLSTM2D)  (None, 30, 53, 53, 14)    11144     \n                                                                 \n max_pooling3d_2 (MaxPoolin  (None, 30, 27, 27, 14)    0         \n g3D)                                                            \n                                                                 \n time_distributed_2 (TimeDi  (None, 30, 27, 27, 14)    0         \n stributed)                                                      \n                                                                 \n conv_lstm2d_3 (ConvLSTM2D)  (None, 30, 25, 25, 16)    17344     \n                                                                 \n max_pooling3d_3 (MaxPoolin  (None, 30, 13, 13, 16)    0         \n g3D)                                                            \n                                                                 \n flatten (Flatten)           (None, 81120)             0         \n                                                                 \n dense (Dense)               (None, 1)                 81121     \n                                                                 \n=================================================================\nTotal params: 114121 (445.79 KB)\nTrainable params: 114121 (445.79 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2023-12-08 20:10:28.925452: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'sequential/conv_lstm2d_3/while/body/_675/sequential/conv_lstm2d_3/while/mul_6' -> 'sequential/conv_lstm2d_3/while/body/_675/sequential/conv_lstm2d_3/while/add_5', 'sequential/conv_lstm2d_3/while/body/_675/sequential/conv_lstm2d_3/while/clip_by_value' -> 'sequential/conv_lstm2d_3/while/body/_675/sequential/conv_lstm2d_3/while/mul_7', 'sequential/conv_lstm2d_3/while/body/_675/sequential/conv_lstm2d_3/while/clip_by_value_2' -> 'sequential/conv_lstm2d_3/while/body/_675/sequential/conv_lstm2d_3/while/mul_9', 'sequential/conv_lstm2d_3/while/body/_675/sequential/conv_lstm2d_3/while/convolution_6' -> 'sequential/conv_lstm2d_3/while/body/_675/sequential/conv_lstm2d_3/while/add_4'}.\n","output_type":"stream"},{"name":"stdout","text":"20/20 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.5375","output_type":"stream"},{"name":"stderr","text":"2023-12-08 20:10:49.119835: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'sequential/conv_lstm2d_3/while/body/_145/sequential/conv_lstm2d_3/while/mul_6' -> 'sequential/conv_lstm2d_3/while/body/_145/sequential/conv_lstm2d_3/while/add_5', 'sequential/conv_lstm2d_3/while/body/_145/sequential/conv_lstm2d_3/while/Tanh_1' -> 'sequential/conv_lstm2d_3/while/body/_145/sequential/conv_lstm2d_3/while/mul_9', 'sequential/conv_lstm2d_3/while/body/_145/sequential/conv_lstm2d_3/while/convolution_7' -> 'sequential/conv_lstm2d_3/while/body/_145/sequential/conv_lstm2d_3/while/add_6'}.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 0.71250, saving model to model\n20/20 [==============================] - 27s 583ms/step - loss: 0.8372 - accuracy: 0.5375 - val_loss: 0.7125 - val_accuracy: 0.5500\nEpoch 2/5\n20/20 [==============================] - ETA: 0s - loss: 0.7237 - accuracy: 0.4625\nEpoch 2: val_loss improved from 0.71250 to 0.69669, saving model to model\n20/20 [==============================] - 9s 470ms/step - loss: 0.7237 - accuracy: 0.4625 - val_loss: 0.6967 - val_accuracy: 0.4500\nEpoch 3/5\n20/20 [==============================] - ETA: 0s - loss: 0.7218 - accuracy: 0.4750\nEpoch 3: val_loss improved from 0.69669 to 0.69644, saving model to model\n20/20 [==============================] - 9s 468ms/step - loss: 0.7218 - accuracy: 0.4750 - val_loss: 0.6964 - val_accuracy: 0.5000\nEpoch 4/5\n20/20 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.5500\nEpoch 4: val_loss did not improve from 0.69644\n20/20 [==============================] - 9s 466ms/step - loss: 0.6816 - accuracy: 0.5500 - val_loss: 0.6999 - val_accuracy: 0.5000\nEpoch 5/5\n20/20 [==============================] - ETA: 0s - loss: 0.6748 - accuracy: 0.6750\nEpoch 5: val_loss did not improve from 0.69644\n20/20 [==============================] - 9s 469ms/step - loss: 0.6748 - accuracy: 0.6750 - val_loss: 0.7070 - val_accuracy: 0.5500\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7e3320cad450>"},"metadata":{}}]},{"cell_type":"code","source":"print(model.predict(np.array(test_data)))","metadata":{"execution":{"iopub.status.busy":"2023-12-09T03:55:21.810812Z","iopub.execute_input":"2023-12-09T03:55:21.811736Z","iopub.status.idle":"2023-12-09T03:55:37.396613Z","shell.execute_reply.started":"2023-12-09T03:55:21.811698Z","shell.execute_reply":"2023-12-09T03:55:37.395634Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"4/4 [==============================] - 9s 567ms/step\n[[0.646325  ]\n [0.9876181 ]\n [0.9875328 ]\n [0.55846125]\n [0.03137861]\n [0.86868477]\n [0.24281074]\n [0.40563938]\n [0.1956675 ]\n [0.05252928]\n [0.8455239 ]\n [0.92914754]\n [0.06591837]\n [0.21675268]\n [0.02986682]\n [0.99600756]\n [0.6772883 ]\n [0.854088  ]\n [0.7729977 ]\n [0.7394715 ]\n [0.15812124]\n [0.05111151]\n [0.22208028]\n [0.98902136]\n [0.872341  ]\n [0.97450495]\n [0.59679383]\n [0.5063136 ]\n [0.06039098]\n [0.88625413]\n [0.9666873 ]\n [0.01814648]\n [0.7502954 ]\n [0.13643427]\n [0.11626054]\n [0.63392663]\n [0.0479828 ]\n [0.95430195]\n [0.05039083]\n [0.32687426]\n [0.982945  ]\n [0.899703  ]\n [0.96414113]\n [0.7445842 ]\n [0.97464776]\n [0.07044173]\n [0.66401756]\n [0.7906195 ]\n [0.7497153 ]\n [0.5262678 ]\n [0.16856591]\n [0.9920827 ]\n [0.9347218 ]\n [0.07659511]\n [0.67866945]\n [0.06176254]\n [0.01692191]\n [0.08508188]\n [0.29329777]\n [0.44022325]\n [0.06899623]\n [0.00761489]\n [0.8695058 ]\n [0.8587578 ]\n [0.7810566 ]\n [0.9769447 ]\n [0.17954572]\n [0.024619  ]\n [0.14375931]\n [0.28020042]\n [0.728688  ]\n [0.47103956]\n [0.81307894]\n [0.02972344]\n [0.99221236]\n [0.40381628]\n [0.00969998]\n [0.12405848]\n [0.06036966]\n [0.77917695]\n [0.30767933]\n [0.4825041 ]\n [0.9448318 ]\n [0.05759268]\n [0.8737724 ]\n [0.69035196]\n [0.02368585]\n [0.7597432 ]\n [0.05084441]\n [0.8199781 ]\n [0.00900203]\n [0.03191576]\n [0.05465844]\n [0.04359567]\n [0.17068864]\n [0.15161766]\n [0.96423167]\n [0.68867445]\n [0.80010545]\n [0.9562469 ]]\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install seaborn","metadata":{"execution":{"iopub.status.busy":"2023-12-08T20:11:43.966420Z","iopub.status.idle":"2023-12-08T20:11:43.966753Z","shell.execute_reply.started":"2023-12-08T20:11:43.966592Z","shell.execute_reply":"2023-12-08T20:11:43.966607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(video_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T03:47:03.404831Z","iopub.execute_input":"2023-12-09T03:47:03.405649Z","iopub.status.idle":"2023-12-09T03:47:03.411644Z","shell.execute_reply.started":"2023-12-09T03:47:03.405613Z","shell.execute_reply":"2023-12-09T03:47:03.410731Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"13292"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport seaborn as sns\n\ny_pred = (model.predict(np.array(test_data)) > 0.5).astype(int)\n\n# Calculate the confusion matrix\ncm = confusion_matrix(np.array(test_labels), y_pred)\n\n# Plot the confusion matrix using seaborn\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 16})\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\nprint('\\nClassification Report:')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:36:56.924907Z","iopub.execute_input":"2023-12-09T04:36:56.925347Z","iopub.status.idle":"2023-12-09T04:37:19.510790Z","shell.execute_reply.started":"2023-12-09T04:36:56.925302Z","shell.execute_reply":"2023-12-09T04:37:19.509854Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"7/7 [==============================] - 13s 667ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:31:48.755190Z","iopub.execute_input":"2023-12-09T04:31:48.755962Z","iopub.status.idle":"2023-12-09T04:31:48.815342Z","shell.execute_reply.started":"2023-12-09T04:31:48.755925Z","shell.execute_reply":"2023-12-09T04:31:48.814354Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"model = tf.keras.models.load_model('model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:36:47.070831Z","iopub.execute_input":"2023-12-09T04:36:47.071736Z","iopub.status.idle":"2023-12-09T04:36:50.230100Z","shell.execute_reply.started":"2023-12-09T04:36:47.071702Z","shell.execute_reply":"2023-12-09T04:36:50.228973Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_labels, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:37:19.514942Z","iopub.execute_input":"2023-12-09T04:37:19.515823Z","iopub.status.idle":"2023-12-09T04:37:19.532196Z","shell.execute_reply.started":"2023-12-09T04:37:19.515783Z","shell.execute_reply":"2023-12-09T04:37:19.531128Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.79      0.86      0.82       108\n           1       0.81      0.72      0.76        90\n\n    accuracy                           0.80       198\n   macro avg       0.80      0.79      0.79       198\nweighted avg       0.80      0.80      0.80       198\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test_video_path = \"/kaggle/input/car-thief/Moment thieves use hi-tech device to steal 25000 keyless BMW.mp4\"","metadata":{"execution":{"iopub.status.busy":"2023-12-08T20:11:43.974387Z","iopub.status.idle":"2023-12-08T20:11:43.974858Z","shell.execute_reply.started":"2023-12-08T20:11:43.974611Z","shell.execute_reply":"2023-12-08T20:11:43.974634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# save the iris classification model as a pickle file\nmodel_pkl_file = \"model.pkl\"  \n\nwith open(model_pkl_file, 'wb') as file:  \n    pickle.dump(model, file)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T04:28:33.832977Z","iopub.execute_input":"2023-12-09T04:28:33.833378Z","iopub.status.idle":"2023-12-09T04:28:33.936378Z","shell.execute_reply.started":"2023-12-09T04:28:33.833345Z","shell.execute_reply":"2023-12-09T04:28:33.935346Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}